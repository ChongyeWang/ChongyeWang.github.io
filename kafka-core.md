## 深入理解Kafka（Note）

Kafka 消费端也具备一定的容灾能力。Consumer 使用拉(Pull) 模式从服务端拉取消息，并且保存消费的具体位置，当消费者宕机后 恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消 费，这样就不会造成消息丢失。

ISR与HW和LEO也有紧密的关系。HW是High Watermark的缩写，俗 称高水位，它标识了一个特定的消息偏移量(offset)，消费者只能 拉取到这个offset之前的消息。

LEO是Log End Offset的缩写，它标识当前日志文件中下一条待写 入消息的offset

LEO的大小相当于当前日志分区中最后一条消息的offset值加1。分区 ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即 为分区的HW，对消费者而言只能消费HW之前的消息。

由此可见，Kafka 的复制机制既不是完全的同步复制，也不是单 纯的异步复制。事实上，同步复制要求所有能工作的 follower 副本 都复制完，这条消息才会被确认为已成功提交，这种复制方式极大地 影响了性能。而在异步复制方式下，follower副本异步地从leader副本中复制数据，数据只要被leader副本写入就被认为已经成功提交。 在这种情况下，如果follower副本都还没有复制完而落后于leader副 本，突然leader副本宕机，则会造成数据丢失。Kafka使用的这种ISR 的方式则有效地权衡了数据可靠性和性能之间的关系。

序列化：生产者需要用序列化器(Serializer)把对象转换成字节数组才 能通过网络发送给Kafka。而在对侧，消费者需要用反序列化器 (Deserializer)把从 Kafka 中收到的字节数组转换成相应的对象。

生产者使用的序列化器和消费者使用的反序列化器是需要一一对 应的，如果生产者使用了某种序列化器，比如StringSerializer，而 消费者使用了另一种序列化器，比如IntegerSerializer，那么是无法 解析出想要的数据的。

拦截器：生产者拦截器既可以用来在消息发送前做一些准备工作，比如按 照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来 在发送回调逻辑前做一些定制化的需求，比如统计类工作。

整个生产者客户端由两个线程协调运行，这两个线程分别为主线 程和Sender线程(发送线程)。在主线程中由KafkaProducer创建消 息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消 息累加器(RecordAccumulator，也称为消息收集器)中。Sender 线 程负责从RecordAccumulator中获取消息并将其发送到Kafka中。

RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批 量发送，进而减少网络传输的资源消耗以提升性能。

如果所有的消费者都隶属于同一个消费组，那么所有的消息都 会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。
如果所有的消费者都隶属于不同的消费组，那么所有的消息都 会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就 相当于发布/订阅模式的应用。

Kafka中的消费是基于拉模式的。消息的消费一般有两种模式:推 模式和拉模式。推模式是服务端主动将消息推送给消费者，而拉模式 是消费者主动向服务端发起请求来拉取消息。

在每次调用poll()方法时，它返回的是还没有被消费过的消息 集(当然这个前提是消息已经存储在Kafka 中了，并且暂不考虑异常 情况的发生)，要做到这一点，就需要记录上一次消费时的消费位 移。并且这个消费位移必须做持久化保存，而不是单单保存在内存 中，否则消费者重启之后就无法知晓之前的消费位移。再考虑一种情 况，当有新的消费者加入时，那么必然会有再均衡的动作，对于同一 分区而言，它可能在再均衡动作之后分配给新的消费者，如果不持久 化保存消费位移，那么这个新的消费者也无法知晓之前的消费位移。
在旧消费者客户端中，消费位移是存储在ZooKeeper中的。而在新 消费者客户端中，消费位移存储在Kafka内部的主题 __consumer_offsets中。这里把将消费位移存储起来(持久化)的动 作称为“提交”，消费者在消费完消息之后需要执行消费位移的提 交。
在Kafka消费的编程逻辑中位移提交是一大难点，自动提交消费位 移的方式非常简便，它免去了复杂的位移提交逻辑，让编码更简洁。 但随之而来的是重复消费和消息丢失的问题。

再均衡：再均衡是指分区的所属权从一个消费者转移到另一消费者的行 为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便 又安全地删除消费组内的消费者或往消费组内添加消费者。不过在再 均衡发生期间，消费组内的消费者是无法读取消息的。也就是说，在 再均衡发生期间的这一小段时间内，消费组会变得不可用。另外，当 一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢 失。比如消费者消费完某个分区中的一部分消息时还没有来得及提交 消费位移就发生了再均衡操作，之后这个分区又被分配给了消费组内 的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。一般情况下，应尽量避免不必要的再均衡的发生。

分区分配策略：
RangeAssignor 分配策略的原理是按照消费者总数和分区总数进 行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以 保证分区尽可能均匀地分配给所有的消费者。对于每一个主题， RangeAssignor策略会将消费组内所有订阅这个主题的消费者按照名称 的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平 均分配，那么字典序靠前的消费者会被多分配一个分区。假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消 费者每个分配n+1个分区，后面的(消费者数量-m)个消费者每个分配 n个分区。

RoundRobinAssignor分配策略的原理是将消费组内所有消费者及 消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐 个将分区依次分配给每个消费者。

StickyAssignor分配策略，“sticky”这个单词 可以翻译为“黏性的”，Kafka从0.11.x版本开始引入这种分配策略， 它主要有两个目的:

(1)分区的分配要尽可能均匀。

(2)分区的分配尽可能与上次分配的保持相同。

当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个 目标，StickyAssignor分配策略的具体实现要比RangeAssignor和 RoundRobinAssignor这两种分配策略要复杂得多。我们举例来看一下 StickyAssignor分配策略的实际效果。
如前所述，使用StickyAssignor分配策略的一个优点就是可以使 分区重分配具备“黏性”，减少不必要的分区移动(即一个分区剥离 之前的消费者，转而分配给另一个新的消费者)。

