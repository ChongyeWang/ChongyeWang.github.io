## Kafka权威指南（Note）

### 主题和分区

Kafka 的消息通过主题进行分类。主题就好比数据库的表，或者文件系统里的文件夹。主 题可以被分为若干个分区，一个分区就是一个提交日志。消息以追加的方式写入分区，然 后以先入先出的顺序读取。要注意，由于一个主题一般包含几个分区，因此无法在整个主 题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。

Kafka 通过分区来实现数据冗余和伸缩性。分 区可以分布在不同的服务器上，也就是说，一个主题可以横跨多个服务器，以此来提供比 单个服务器更强大的性能。


### 生产者和消费者

一般情况下，一个消息会被发布到一个特定的主题上。生产者在默认情况下把消息均衡地分布到 主题的所有分区上，而并不关心特定消息会被写到哪个分区。不过，在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。


消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka 会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。消费 者把每个分区最后读取的消息偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或重 启，它的读取状态不会丢失。


消费者是消费者群组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群 组保证每个分区只能被一个消费者使用。

通过这种方式，消费者可以消费包含大量消息的主题。而且，如果一个消费者失效，群组 里的其他消费者可以接管失效消费者的工作。


### broker和集群

broker 是集群的组成部分。每个集群都有一个 broker 同时充当了集群控制器的角色(自动 从集群的活跃成员中选举出来)。控制器负责管理工作，包括将分区分配给 broker 和监控 broker。在集群中，一个分区从属于一个 broker，该 broker 被称为分区的首领。


保留消息(在一定期限内)是 Kafka 的一个重要特性。Kafka broker 默认的消息保留策略 是这样的:要么保留一段时间(比如 7 天)，要么保留到消息达到一定大小的字节数(比 如 1GB)。当消息数量达到这些上限时，旧消息就会过期并被删除，所以在任何时刻，可 用消息的总量都不会超过配置参数所指定的大小。主题可以配置自己的保留策略，可以将 消息保留到不再使用它们为止。例如，用于跟踪用户活动的数据可能需要保留几天，而应 用程序的度量指标可能只需要保留几个小时。可以通过配置把主题当作紧凑型日志，只有 最后一个带有特定键的消息会被保留下来。这种情况对于变更日志类型的数据来说比较适 用，因为人们只关心最后时刻发生的那个变更。


### 分区


如果键值为 null，并且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用 的分区上。分区器使用轮询(Round Robin)算法将消息均衡地分布到各个分区上。

如果键不为空，并且使用了默认的分区器，那么 Kafka 会对键进行散列(使用 Kafka 自己 的散列算法，即使升级 Java 版本，散列值也不会发生变化)，然后根据散列值把消息映射 到特定的分区上。这里的关键之处在于，同一个键总是被映射到同一个分区上，所以在进 行映射时，我们会使用主题所有的分区，而不仅仅是可用的分区。这也意味着，如果写入 数据的分区是不可用的，那么就会发生错误。

只有在不改变主题分区数量的情况下，键与分区之间的映射才能保持不变。


### 消费者和消费者群组

Kafka 消费者从属于消费者群组。一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息。

往群组里增加消费者是横向伸缩消费能力的主要方式。Kafka 消费者经常会做一些高延迟 的操作，比如把数据写到数据库或 HDFS，或者使用数据进行比较耗时的计算。在这些情 况下，单个消费者无法跟上数据生成的速度，所以可以增加更多的消费者，让它们分担负 载，每个消费者只处理部分分区的消息，这就是横向伸缩的主要手段。我们有必要为主题 创建大量的分区，在负载增长时可以加入更多的消费者。不过要注意，不要让消费者的数 量超过主题分区的数量，多余的消费者只会被闲置。

除了通过增加消费者来横向伸缩单个应用程序外，还经常出现多个应用程序从同一个主题 读取数据的情况。实际上，Kafka 设计的主要目标之一，就是要让 Kafka 主题里的数据能 够满足企业各种应用场景的需求。在这些场景里，每个应用程序可以获取到所有的消息， 而不只是其中的一部分。只要保证每个应用程序有自己的消费者群组，就可以让它们获取到主题所有的消息。不同于传统的消息系统，横向伸缩 Kafka 消费者和消费者群组并不会对性能造成负面影响。

### 消费者群组和分区再均衡

分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。再均衡非常 重要，它为消费者群组带来了高可用性和伸缩性(我们可以放心地添加或移除消费者)， 不过在正常情况下，我们并不希望发生这样的行为。在再均衡期间，消费者无法读取消 息，造成整个群组一小段时间的不可用。另外，当分区被重新分配给另一个消费者时，消 费者当前的读取状态会丢失，它有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢 应用程序。

消费者通过向被指派为群组协调器的 broker(不同的群组可以有不同的协调器)发送心跳 来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间 间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费者会在轮询消息(为了获取消息)或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会 话就会过期，群组协调器认为它已经死亡，就会触发一次再均衡。

### 提交和偏移量

消费者往一个叫作 _consumer_offset 的特殊主题发送 消息，消息里包含每个分区的偏移量。如果消费者一直处于运行状态，那么偏移量就没有 什么用处。不过，如果消费者发生崩溃或者有新的消费者加入群组，就会触发再均衡，完 成再均衡之后，每个消费者可能分配到新的分区，而不是之前处理的那个。为了能够继续 之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。


### 文件管理

因为在一个大文件里查找和删除消息是很费时的，也很容易出错，所以我们把分区分成若 干个片段。默认情况下，每个片段包含 1GB 或一周的数据，以较小的那个为准。在 broker 往分区写入数据时，如果达到片段上限，就关闭当前文件，并打开一个新文件。

当前正在写入数据的片段叫作活跃片段。活动片段永远不会被删除，所以如果你要保留数 据 1 天，但片段里包含了 5 天的数据，那么这些数据会被保留 5 天，因为在片段被关闭之 前这些数据无法被删除。如果你要保留数据一周，而且每天使用一个新片段，那么你就会 看到，每天在使用一个新片段的同时会删除一个最老的片段——所以大部分时间该分区会 有 7 个片段存在。

### 索引

消费者可以从 Kafka 的任意可用偏移量位置开始读取消息。假设消费者要读取从偏移量 100 开始的 1MB 消息，那么 broker 必须立即定位到偏移量 100(可能是在分区的任意一个片段 里)，然后开始从这个位置读取消息。为了帮助 broker 更快地定位到指定的偏移量，Kafka 为每个分区维护了一个索引。索引把偏移量映射到片段文件和偏移量在文件里的位置。

索引也被分成片段，所以在删除消息时，也可以删除相应的索引。Kafka 不维护索引的 校验和。如果索引出现损坏，Kafka 会通过重新读取消息并录制偏移量和位置来重新生 成索引。如果有必要，管理员可以删除索引，这样做是绝对安全的，Kafka 会自动重新 生成这些索引。

### 可靠性保证
* Kafka 可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且 消息 B 在消息 A 之后写入，那么 Kafka 可以保证消息 B 的偏移量比消息 A 的偏移量大， 而且消费者会先读取消息 A 再读取消息 B。
* 只有当消息被写入分区的所有同步副本时(但不一定要写入磁盘)，它才被认为是“已 提交”的。生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认，或 者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。
* 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。
* 消费者只能读取已经提交的消息。

